# vibecoding is real, almost all of this code generated by AI

import subprocess
import yaml
import json
import os
import re
from pathlib import Path
from datetime import datetime

# Folder containing the changelog YAML files
CHANGELOG_ARCHIVE_FOLDER = 'html/changelogs/archive'
CHANGELOG_ALL_FOLDER = 'html/changelogs/'
OUTPUT_JSON_PATH = 'ss1984_changelog_highlight_generated.json'
BOT_AUTHOR = '1984-ci-event'  # For future commit filtering if needed
BOT_AUTHOR_FULLNAME = '1984-ci-event[bot]'

BASE_DIR = Path(__file__).resolve().parent  # Directory where your script lives
GIT_REPO_PATH = BASE_DIR.parent  # This is platform-independent Path object
git_repo_path_str = str(GIT_REPO_PATH)

SKIP_BELOW_YEAR = 2025
SKIP_PR_PARTIAL_BEFORE_DATE = "2025-06-07" # was not configured properly for entries before that date
#BOT_COMMIT_MSG = "Automatic changelog compile [ci skip]"
AUTOCHANGELOG_REGEX = re.compile(r"AutoChangeLog-pr-(\d+)\.ya?ml$")
ARCHIVE_FILENAME_REGEX = re.compile(r'^\d{4}-\d{2}$') # match filenames like "2009-01", "2025-07", etc.
AUTHOR_REGEX = re.compile(r'^-author:\s*"([^"]+)"')
CHANGES_START_LINE = "-changes:"
REGEX_START_CHANGE = re.compile(r'  - ')
REGEX_PARTIAL_MATCHES = re.compile(r'(?:^| {2,})(\w+):\s*(.*?)(?=(?:^| {2,})\w+:|$)')
AUTOCHANGELOG_REGEX_NEW = re.compile(r'^--- a/(.+)')
AUTOCHANGELOG_PATH_REGEX = re.compile(r'--- a\/(.+)')
ARCHIVE_REGEX_NEW = re.compile(r'^\+\+\+ b/html/changelogs/archive/(\d{4}-\d{2})\.yml$')
cutoff_str = "-  - "

def is_archive_file(file_path: str) -> bool:
    p = Path(file_path)

    # Check path contains the archive folder segment
    if CHANGELOG_ARCHIVE_FOLDER not in str(p.parent).replace('\\', '/'):
        return False

    # Get just the filename stem (without extension)
    filename_stem = p.stem  # '2009-01' if filename is '2009-01.yml'

    # Check filename matches YYYY-MM format
    return ARCHIVE_FILENAME_REGEX.match(filename_stem)

def extract_change_text(changes_list):
    texts = []
    for change_dict in changes_list:
        if isinstance(change_dict, dict):
            # Extract all values as strings
            texts.extend(str(v) for v in change_dict.values())
        else:
            texts.append(str(change_dict))
    return texts  # <-- return list directly instead of joining

def normalize_change(change):
    change = re.sub(r'^\s*-\s*', '', change)
    change = re.sub(r'^(?:\S+?:\s*)', '', change)
    change = normalize_whitespace(change)
    if len(change) > 0 and change[0] == '\"':
        change = change[1:]
    return change.strip()

def parse_changes(changes_str):
    parts = [part.strip() for part in changes_str.split(' - ') if part.strip()]
    return [normalize_change(c) for c in parts]

def parse_author_and_changes(line):
    """Parse a single author and their changes from line."""
    m = re.match(r'^(\S+):\s+(.*)$', line.strip())
    if not m:
        return None, None
    author = m.group(1)
    changes_str = m.group(2)
    return author, changes_str

def split_multiple_authors(full_archive_string):
    """Split multiple authors if separated by 2+ spaces or newline; else return single author list."""
    # Heuristic: authors separated by two or more spaces or newline, but note this is heuristic only
    pattern = re.compile(r'(\S+):\s+(.*?)(?=\s{2,}\S+:|$)', re.DOTALL)
    matches = list(pattern.finditer(full_archive_string))

    if len(matches) > 1:
        return [(m.group(1), m.group(2).strip()) for m in matches]
    else:
        # No multiple authors found, treat entire string as one author block
        author, changes_str = parse_author_and_changes(full_archive_string)
        if author is None:
            return []
        return [(author, changes_str)]

def extract_date_prefix(s):
    # Extract leading date if present, format: YYYY-MM-DD:
    m = re.match(r'^(\d{4}-\d{2}-\d{2}):\s*(.*)', s, re.DOTALL)
    if m:
        return m.group(1), m.group(2)
    else:
        return None, s  # no date found, return original string

def normalize_whitespace(line):
    # 1. Separate leading whitespace from actual content
    leading_ws_match = re.match(r'^(\s*)(.*)$', line)
    if not leading_ws_match:
        return line.strip()
    leading_ws = leading_ws_match.group(1)
    content = leading_ws_match.group(2)

    # 2. Collapse internal whitespace in content only (replace multiple spaces/tabs/newlines with a single space)
    content = re.sub(r'\s+', ' ', content)

    # 3. Remove trailing spaces (already effectively done by collapsing, but be explicit)
    content = content.rstrip()

    # 4. Recombine
    return leading_ws + content

def split_authors(s):
    author_pattern = re.compile(
        r'(?<!- )(\S+):\s+(.*?)(?=\s+(?<!- )\S+:|$)', re.DOTALL
    )

    return [(m.group(1), m.group(2).strip()) for m in author_pattern.finditer(s)]

def process_data(autoChangelog_files_prev, file_insertions, prev_date):
    autochangelog_full = "".join(autoChangelog_files_prev).strip()
    if not autochangelog_full:
        return
    all_matches = REGEX_PARTIAL_MATCHES.findall(autochangelog_full)

    for (author, changes) in enumerate(all_matches, 1):
        auto_changes = parse_changes(changes)
        if not auto_changes:
            return
        file_insertions.append({
            'date': prev_date,
            'author': author,
            'changes': auto_changes
        })

def get_bot_commit_diffs():
    # Get bot commit hashes touching the changelog folder
    cmd_hashes = [
        'git', '-C', git_repo_path_str, 'log',
        '--author=' + BOT_AUTHOR,
        '--pretty=format:%H',
        '--', CHANGELOG_ARCHIVE_FOLDER
    ]
    commit_hashes = subprocess.check_output(cmd_hashes, text=True).splitlines()

    file_insertions = list()
    last_date = None
    prev_date = None

    autoChangelog_files = list()
    autoChangelog_files_prev = list()
    skip_file = True
    is_changes = False
    last_author = None
    was_different_data = False


    for commit_hash in commit_hashes:
        # Get commit date string (ISO 8601 format)
        cmd_date = ['git', '-C', git_repo_path_str, 'show', '-s', '--format=%cI', commit_hash]
        commit_date_str = subprocess.check_output(cmd_date, text=True).strip()
        commit_date = datetime.fromisoformat(commit_date_str)

        if (commit_date.year < SKIP_BELOW_YEAR):
            continue

        # Keep cmd_diff as originally named
        cmd_diff = ['git', '-C', git_repo_path_str, 'show', '-U0', '--format=', commit_hash, '--', CHANGELOG_ALL_FOLDER]
        diff_text = subprocess.check_output(cmd_diff, text=True)
        formatted_date = commit_date.strftime('%Y-%m-%d')

        if last_date != formatted_date:
            autoChangelog_files_prev = autoChangelog_files
            prev_date = last_date
            autoChangelog_files = list()
            skip_file = True
            is_changes = False
            last_author = None
            was_different_data = True
            last_date = formatted_date
        else:
            was_different_data = False

        for line in diff_text.splitlines():
            is_autochangelog_match = AUTOCHANGELOG_REGEX_NEW.match(line)
            if is_autochangelog_match:
                fname_match = is_autochangelog_match.group(1)
                if fname_match:
                    was_touched_by_bot_cmd = ["git", "log", "-1", "--diff-filter=A", "--format=%an", "--since=" + SKIP_PR_PARTIAL_BEFORE_DATE, "--", fname_match]
                    was_touched_by_bots = subprocess.check_output(was_touched_by_bot_cmd, text=True).strip()
                    is_our_changelog = False
                    if was_touched_by_bots:
                        was_touched_arr = was_touched_by_bots.splitlines()
                        is_our_changelog = BOT_AUTHOR_FULLNAME in was_touched_arr
                    if is_our_changelog:
                        skip_file = False
                        is_changes = False
                    else:
                        skip_file = True
                else:
                    skip_file = True
                continue

            if (skip_file):
                continue

            if not line.startswith('-'): # some invalid or git stuff things like delete node...
                continue

            m_author = AUTHOR_REGEX.search(line)
            if (m_author):
                author = m_author.group(1)
                if author != last_author:
                    author_text = "  " + author + ":"
                    autoChangelog_files.append(author_text) # don't really care about order of insertions
                last_author = author
                is_changes = False
                continue

            if is_changes:
                if not line.startswith(cutoff_str):
                    is_changes = False
                    continue
                cleaned_line = line[1:]
                cleaned_line = normalize_change(cleaned_line)
                autoChangelog_files.append(cleaned_line)

            if (line == CHANGES_START_LINE):
                is_changes = True
                continue


        if not was_different_data:
            continue
        if len(autoChangelog_files_prev) < 1: # we at beginning
            continue
        process_data(autoChangelog_files_prev, file_insertions, prev_date)

    if len(autoChangelog_files_prev) > 0:
        process_data(autoChangelog_files_prev, file_insertions, prev_date)

    return file_insertions

def parse_full_changelogs(folder):
    folder_path = Path(folder).resolve()
    full_changelogs = {}
    for root, dirs, files in os.walk(folder):
        for file in files:
            if not file.endswith('.yml'):
                continue
            year_match = re.match(r"(\d{4})-\d{2}\.ya?ml$", file)
            if year_match:
                year = int(year_match.group(1))
                if year < SKIP_BELOW_YEAR:
                    # Skip files older than 2025
                    continue
            path = Path(root) / file
            with open(path, 'r', encoding='utf-8') as f:
                yaml_data = yaml.safe_load(f)
            relative_path = path.resolve().relative_to(folder_path).as_posix()
            full_changelogs[relative_path] = yaml_data
    return full_changelogs

def yaml_entries_from_text(yaml_text):
    try:
        # Parse YAML fragment that contains authors at root level
        return yaml.safe_load(yaml_text)
    except Exception:
        return None

def main():
    file_insertions = get_bot_commit_diffs()
    output_path_actual = os.path.join((str(BASE_DIR)), OUTPUT_JSON_PATH)
    serialized_entries = file_insertions
    with open(output_path_actual, 'w', encoding='utf-8') as f:
        json.dump(serialized_entries, f, indent=2, ensure_ascii=False)

    print(f"Saved {len(serialized_entries)} entries from bot commits based on diff insertions.")

if __name__ == '__main__':
    main()
